// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

use crate::expressions::Column;
use crate::utils::get_indices_of_exprs_strict;
use crate::{
    physical_exprs_contains, LexOrdering, LexOrderingRef, LexOrderingReq, PhysicalExpr,
    PhysicalSortExpr, PhysicalSortRequirement,
};

use arrow::datatypes::SchemaRef;

use crate::physical_expr::{deduplicate_physical_exprs, have_common_entries};
use crate::sort_properties::{ExprOrdering, SortProperties};
use arrow_schema::SortOptions;
use datafusion_common::tree_node::{Transformed, TreeNode};
use datafusion_common::utils::longest_consecutive_prefix;
use datafusion_common::{DataFusionError, JoinSide, JoinType, Result};
use itertools::izip;
use std::hash::Hash;
use std::sync::Arc;

/// EquivalentClass is a set of [`Arc<dyn PhysicalExpr>`]s that are known
/// to have the same value in all tuples in a relation. These are generated by equality predicates,
/// typically equi-join conditions and equality conditions in filters.
#[derive(Debug, Clone)]
pub struct EquivalentGroups {
    inner: Vec<Vec<Arc<dyn PhysicalExpr>>>,
}

impl EquivalentGroups {
    /// Creates an empty ordering equivalent group
    fn empty() -> Self {
        EquivalentGroups { inner: vec![] }
    }

    /// Creates ordering equivalent groups from given vectors
    /// Each vector corresponds to a group
    fn new(entries: Vec<Vec<Arc<dyn PhysicalExpr>>>) -> Self {
        let mut res = EquivalentGroups { inner: entries };
        res.remove_redundant_entries();
        res
    }

    /// Get how many equivalent groups there are.
    fn len(&self) -> usize {
        self.inner.len()
    }

    /// Check whether equivalent groups is empty
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Iterate over inner vector.
    fn iter(&self) -> impl Iterator<Item = &Vec<Arc<dyn PhysicalExpr>>> {
        self.inner.iter()
    }

    /// Adds tuple argument to the equivalent groups
    /// It is known that first and second entry in the tuple will have same values in the table.
    /// This can arise after filter(a=b), alias(a, a as b), etc.
    pub fn add_equal_conditions(
        &mut self,
        new_conditions: (&Arc<dyn PhysicalExpr>, &Arc<dyn PhysicalExpr>),
    ) {
        let (first, second) = new_conditions;
        let mut first_group = None;
        let mut second_group = None;
        for (group_idx, eq_class) in self.inner.iter().enumerate() {
            if physical_exprs_contains(eq_class, first) {
                first_group = Some(group_idx);
            }
            if physical_exprs_contains(eq_class, second) {
                second_group = Some(group_idx);
            }
        }
        match (first_group, second_group) {
            (Some(first_group_idx), Some(second_group_idx)) => {
                // We should bridge these groups
                if first_group_idx != second_group_idx {
                    let other_class = self.inner[second_group_idx].clone();
                    // TODO: Use group at the lower index during merging
                    // This would improve performance during remove.
                    self.inner[first_group_idx].extend(other_class);
                    self.inner.remove(second_group_idx);
                }
            }
            (Some(group_idx), None) => {
                // Extend existing group with new entry
                self.inner[group_idx].push(second.clone());
            }
            (None, Some(group_idx)) => {
                // Extend existing group with new entry
                self.inner[group_idx].push(first.clone());
            }
            (None, None) => {
                // None of the expressions, is among existing groups
                // Create a new group.
                self.inner.push(vec![first.clone(), second.clone()]);
            }
        }
    }

    /// Remove redundant entries from the state.
    fn remove_redundant_entries(&mut self) {
        // Remove duplicate entries from each group.
        self.inner = self
            .inner
            .iter()
            .filter_map(|eq_group| {
                let unique_eq_group = deduplicate_physical_exprs(eq_group);
                // Keep groups that have at least 2 entries
                (unique_eq_group.len() > 1).then_some(unique_eq_group)
            })
            .collect();
        // Bridge groups that have common expressions
        self.bridge_groups()
    }

    /// This utils bridges groups that have common expressions
    fn bridge_groups(&mut self) {
        let mut out_groups = vec![];
        for group in &self.inner {
            if out_groups.is_empty() {
                out_groups.push(group.clone());
            } else {
                let mut bridged_group = group.clone();
                // Delete groups in the `out_groups` that have common entry with `group`.
                // Append deleted groups to the `bridged_group`
                out_groups.retain(|distinct_group| {
                    let have_common = have_common_entries(distinct_group, group);
                    if have_common {
                        bridged_group.extend(distinct_group.clone());
                    }
                    !have_common
                });
                // before inserting make sure that entries are deduplicated
                let bridged_group = deduplicate_physical_exprs(&bridged_group);
                out_groups.push(bridged_group);
            }
        }
        self.inner = out_groups;
    }

    /// Extend equivalent group with other equivalent groups
    fn extend(&mut self, other: EquivalentGroups) {
        self.inner.extend(other.inner);
        self.remove_redundant_entries();
    }

    /// Normalizes physical expression according to `EquivalentClass`es inside `self.classes`.
    /// expression is replaced with `EquivalentClass::head` expression if it is among `EquivalentClass::others`.
    pub fn normalize_expr(&self, expr: Arc<dyn PhysicalExpr>) -> Arc<dyn PhysicalExpr> {
        expr.clone()
            .transform(&|expr| {
                for class in self.iter() {
                    if physical_exprs_contains(class, &expr) {
                        return Ok(Transformed::Yes(class[0].clone()));
                    }
                }
                Ok(Transformed::No(expr))
            })
            .unwrap_or(expr)
    }

    /// This function applies the \[`normalize_expr`]
    /// function for all expression in `exprs` and returns a vector of
    /// normalized physical expressions.
    pub fn normalize_exprs(
        &self,
        exprs: &[Arc<dyn PhysicalExpr>],
    ) -> Vec<Arc<dyn PhysicalExpr>> {
        exprs
            .iter()
            .map(|expr| self.normalize_expr(expr.clone()))
            .collect::<Vec<_>>()
    }

    /// This function normalizes `sort_requirement` according to `EquivalenceClasses` in the `self`.
    /// If the given sort requirement doesn't belong to equivalence set inside
    /// `self`, it returns `sort_requirement` as is.
    pub fn normalize_sort_requirement(
        &self,
        mut sort_requirement: PhysicalSortRequirement,
    ) -> PhysicalSortRequirement {
        sort_requirement.expr = self.normalize_expr(sort_requirement.expr);
        sort_requirement
    }

    /// This function normalizes `sort_requirement` according to `EquivalenceClasses` in the `self`.
    /// If the given sort requirement doesn't belong to equivalence set inside
    /// `self`, it returns `sort_requirement` as is.
    pub fn normalize_sort_expr(
        &self,
        mut sort_expr: PhysicalSortExpr,
    ) -> PhysicalSortExpr {
        sort_expr.expr = self.normalize_expr(sort_expr.expr);
        sort_expr
    }

    /// This function applies the \[`normalize_sort_requirement`]
    /// function for all sort requirements in `sort_reqs` and returns a vector of
    /// normalized sort expressions.
    pub fn normalize_sort_requirements(
        &self,
        sort_reqs: &[PhysicalSortRequirement],
    ) -> Vec<PhysicalSortRequirement> {
        let normalized_sort_reqs = sort_reqs
            .iter()
            .map(|sort_req| self.normalize_sort_requirement(sort_req.clone()))
            .collect::<Vec<_>>();
        collapse_lex_req(normalized_sort_reqs)
    }

    /// Similar to the \[`normalize_sort_requirements`] this function normalizes
    /// sort expressions in `sort_exprs` and returns a vector of
    /// normalized sort expressions.
    pub fn normalize_sort_exprs(
        &self,
        sort_exprs: &[PhysicalSortExpr],
    ) -> Vec<PhysicalSortExpr> {
        // Convert `PhysicalSortExpr`s to `PhysicalSortRequirement`s
        let sort_requirements =
            PhysicalSortRequirement::from_sort_exprs(sort_exprs.iter());
        let normalized_sort_requirement =
            self.normalize_sort_requirements(&sort_requirements);
        // Convert back `PhysicalSortRequirement`s to `PhysicalSortExpr`s
        PhysicalSortRequirement::to_sort_exprs(normalized_sort_requirement)
    }

    /// Projects given expression according to mapping in the `source_to_target_mapping`.
    /// If expression is not valid after projection returns `None`.
    fn project_expr(
        &self,
        source_to_target_mapping: &ProjectionMapping,
        expr: &Arc<dyn PhysicalExpr>,
    ) -> Option<Arc<dyn PhysicalExpr>> {
        let children = expr.children();
        if children.is_empty() {
            for (source, target) in source_to_target_mapping.iter() {
                // if source matches expr, expr can be projected
                if source.eq(expr) {
                    return Some(target.clone());
                }
                // if equivalent group of source contains expr, expr can be projected
                else if let Some(group) = self.get_equivalent_group(source) {
                    if physical_exprs_contains(&group, expr) {
                        return Some(target.clone());
                    }
                }
            }
            // After projection, expression is not valid.
            None
        }
        // All of the childrens can be projected
        else if let Some(children) = children
            .into_iter()
            .map(|child| self.project_expr(source_to_target_mapping, &child))
            .collect::<Option<Vec<_>>>()
        {
            Some(expr.clone().with_new_children(children).unwrap())
        } else {
            None
        }
    }

    /// Projects given ordering according to mapping in the `source_to_target_mapping`.
    /// If ordering is not valid after projection returns `None`.
    fn project_ordering(
        &self,
        source_to_target_mapping: &ProjectionMapping,
        ordering: &[PhysicalSortExpr],
    ) -> Option<Vec<PhysicalSortExpr>> {
        let mut res = vec![];
        for order in ordering {
            if let Some(new_expr) =
                self.project_expr(source_to_target_mapping, &order.expr)
            {
                res.push(PhysicalSortExpr {
                    expr: new_expr,
                    options: order.options,
                })
            } else {
                // Expression is not valid, rest of the ordering shouldn't be projected also.
                // e.g if input ordering is [a ASC, b ASC, c ASC], and column b is not valid
                // after projection
                // we should return projected ordering as [a ASC] not as [a ASC, c ASC] even if
                // column c is valid after projection.
                break;
            }
        }
        if res.is_empty() {
            None
        } else {
            Some(res)
        }
    }

    /// Projects EquivalentGroups according to projection mapping described in `source_to_target_mapping`.
    pub fn project(
        &self,
        source_to_target_mapping: &ProjectionMapping,
    ) -> EquivalentGroups {
        let mut projected_eq_groups = vec![];
        for eq_class in self.iter() {
            let new_eq_class = eq_class
                .iter()
                .filter_map(|expr| self.project_expr(source_to_target_mapping, expr))
                .collect::<Vec<_>>();
            if new_eq_class.len() > 1 {
                projected_eq_groups.push(new_eq_class.clone());
            }
        }
        let new_eq_groups =
            Self::calculate_new_projection_equivalent_groups(source_to_target_mapping);
        projected_eq_groups.extend(new_eq_groups);

        // Return projected equivalent groups
        EquivalentGroups::new(projected_eq_groups)
    }

    /// Construct equivalent groups according to projection mapping.
    /// In the result, each inner vector contains equivalents sets. Outer vector corresponds to
    /// distinct equivalent groups
    fn calculate_new_projection_equivalent_groups(
        source_to_target_mapping: &ProjectionMapping,
    ) -> Vec<Vec<Arc<dyn PhysicalExpr>>> {
        // TODO: Convert below algorithm to the version that use HashMap.
        //  once `Arc<dyn PhysicalExpr>` can be stored in `HashMap`.
        let mut res = vec![];
        for (source, target) in source_to_target_mapping {
            if res.is_empty() {
                res.push((source, vec![target.clone()]));
            }
            if let Some(idx) = res.iter_mut().position(|(key, _values)| key.eq(source)) {
                let (_, values) = &mut res[idx];
                if !physical_exprs_contains(values, target) {
                    values.push(target.clone());
                }
            }
        }

        // Filter out groups with single entry, there is nothing
        // else equal to these expressions. Hence tracking them is meaningless
        res.into_iter()
            .filter_map(|(_key, values)| (values.len() > 1).then_some(values))
            .collect()
    }

    /// Returns the equivalent group that contains `expr`
    /// If none of the groups contains `expr`, returns None.
    fn get_equivalent_group(
        &self,
        expr: &Arc<dyn PhysicalExpr>,
    ) -> Option<Vec<Arc<dyn PhysicalExpr>>> {
        for eq_class in self.iter() {
            if physical_exprs_contains(eq_class, expr) {
                return Some(eq_class.to_vec());
            }
        }
        None
    }

    /// Combine EquivalentGroups of the given join children.
    pub fn join(
        &self,
        join_type: &JoinType,
        right_eq_classes: &EquivalentGroups,
        left_columns_len: usize,
        on: &[(Column, Column)],
    ) -> Result<EquivalentGroups> {
        let mut res = EquivalentGroups::empty();
        match join_type {
            JoinType::Inner | JoinType::Left | JoinType::Full | JoinType::Right => {
                res.extend(self.clone());
                let updated_eq_classes = right_eq_classes
                    .iter()
                    .map(|eq_class| {
                        add_offset_to_exprs(eq_class.to_vec(), left_columns_len)
                    })
                    .collect::<Result<Vec<_>>>()?;

                res.extend(EquivalentGroups::new(updated_eq_classes));
            }
            JoinType::LeftSemi | JoinType::LeftAnti => {
                res.extend(self.clone());
            }
            JoinType::RightSemi | JoinType::RightAnti => {
                res.extend(right_eq_classes.clone());
            }
        }
        // In the inner join, expressions in the on are equal at the resulting table.
        if *join_type == JoinType::Inner {
            on.iter().for_each(|(lhs, rhs)| {
                let new_lhs = Arc::new(lhs.clone()) as _;
                let new_rhs =
                    Arc::new(Column::new(rhs.name(), rhs.index() + left_columns_len))
                        as _;
                res.add_equal_conditions((&new_lhs, &new_rhs));
            });
        }
        Ok(res)
    }
}

/// Stores the mapping between source expression and target expression during projection
/// Indices in the vector corresponds to index after projection.
pub type ProjectionMapping = Vec<(Arc<dyn PhysicalExpr>, Arc<dyn PhysicalExpr>)>;

/// `LexOrdering` stores the lexicographical ordering for a schema.
/// OrderingEquivalentClass keeps track of different alternative orderings than can
/// describe the schema.
/// For instance, for the table below
/// |a|b|c|d|
/// |1|4|3|1|
/// |2|3|3|2|
/// |3|1|2|2|
/// |3|2|1|3|
/// both `vec![a ASC, b ASC]` and `vec![c DESC, d ASC]` describe the ordering of the table.
/// For this case, we say that `vec![a ASC, b ASC]`, and `vec![c DESC, d ASC]` are ordering equivalent.
#[derive(Debug, Clone, Eq, PartialEq, Hash)]
pub struct OrderingEquivalentGroup {
    inner: Vec<LexOrdering>,
}

impl OrderingEquivalentGroup {
    /// Creates new empty ordering equivalent group
    fn empty() -> Self {
        OrderingEquivalentGroup { inner: vec![] }
    }

    /// Creates new ordering equivalent from given vector
    pub fn new(entries: Vec<LexOrdering>) -> Self {
        let mut res = OrderingEquivalentGroup { inner: entries };
        // Make sure ordering equivalences doesn't contain something redundant
        res.remove_redundant_entries();
        res
    }

    /// Check whether ordering is in the state.
    pub fn contains(&self, other: &LexOrdering) -> bool {
        self.inner.contains(other)
    }

    /// Pushes new ordering to the state.
    fn push(&mut self, other: LexOrdering) {
        if !self.contains(&other) {
            self.inner.push(other);
        }
        // Make sure that after new entry there is no redundant
        // entry in the state.
        self.remove_redundant_entries();
    }

    /// Check whether ordering equivalent group is empty
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    pub fn iter(&self) -> impl Iterator<Item = &LexOrdering> {
        self.inner.iter()
    }

    fn into_iter(self) -> impl Iterator<Item = LexOrdering> {
        self.inner.into_iter()
    }

    /// Get length of the entries in the ordering equivalent group
    fn len(&self) -> usize {
        self.inner.len()
    }

    /// Extend ordering equivalent group with other group
    pub fn extend(&mut self, other: OrderingEquivalentGroup) {
        for ordering in other.iter() {
            if !self.contains(ordering) {
                self.inner.push(ordering.clone())
            }
        }
        self.remove_redundant_entries();
    }

    /// Adds new ordering into the ordering equivalent group.
    pub fn add_new_orderings(&mut self, orderings: &[LexOrdering]) {
        for ordering in orderings.iter() {
            self.push(ordering.clone());
        }
        self.remove_redundant_entries();
    }

    /// Removes redundant orderings from the state.
    /// For instance, If we already know that
    /// ordering: [a ASC, b ASC, c DESC] is valid for the schema.
    /// There is no need to keep ordering [a ASC, b ASC] in the state.
    fn remove_redundant_entries(&mut self) {
        // Make sure there is no redundant entry
        let mut res: Vec<LexOrdering> = vec![];
        for ordering in self.iter() {
            let mut is_inside = false;
            for item in &mut res {
                if let Some(finer) = Self::get_finer_strict(item, ordering) {
                    *item = finer;
                    is_inside = true;
                }
            }
            if !is_inside {
                res.push(ordering.clone());
            }
        }
        self.inner = res;
    }

    /// Get first ordering entry in the ordering equivalences
    /// This is one of the many valid orderings (if available)
    pub fn output_ordering(&self) -> Option<Vec<PhysicalSortExpr>> {
        self.inner.first().cloned()
    }

    // Append other as postfix to existing ordering equivalences
    pub fn join_postfix(
        &self,
        other: &OrderingEquivalentGroup,
    ) -> OrderingEquivalentGroup {
        if other.is_empty() {
            return OrderingEquivalentGroup::new(self.inner.clone());
        }
        let mut res = vec![];
        for ordering in self.iter() {
            for postfix in other.iter() {
                let mut new_ordering = ordering.clone();
                new_ordering.extend(postfix.clone());
                res.push(new_ordering)
            }
        }
        OrderingEquivalentGroup::new(res)
    }

    /// Adds `offset` value to the index of each expression inside `OrderingEquivalentGroup`.
    pub fn add_offset(&self, offset: usize) -> Result<OrderingEquivalentGroup> {
        let res = self
            .inner
            .iter()
            .map(|ordering| add_offset_to_lex_ordering(ordering, offset))
            .collect::<Result<Vec<_>>>()?;
        Ok(OrderingEquivalentGroup::new(res))
    }

    /// Return finer ordering between lhs and rhs.
    fn get_finer_strict(
        lhs: &[PhysicalSortExpr],
        rhs: &[PhysicalSortExpr],
    ) -> Option<Vec<PhysicalSortExpr>> {
        if izip!(lhs.iter(), rhs.iter()).all(|(lhs, rhs)| lhs.eq(rhs)) {
            if lhs.len() > rhs.len() {
                return Some(lhs.to_vec());
            } else {
                return Some(rhs.to_vec());
            }
        }
        None
    }

    /// Get leading ordering of the expression if it is ordered.
    /// `None` means expression is not ordered.
    fn get_ordering(&self, expr: &Arc<dyn PhysicalExpr>) -> Option<SortOptions> {
        for ordering in self.iter() {
            let leading_ordering = &ordering[0];
            if expr.eq(&leading_ordering.expr) {
                return Some(leading_ordering.options);
            }
        }
        None
    }
}

/// `SchemaProperties` keeps track of useful information related to schema.
/// Currently, it keeps track of
/// - Equivalent columns, e.g columns that have same value.
/// - Valid ordering sort expressions for the schema.
///   Consider table below
/// ```text
/// ┌-------┐
/// | a | b |
/// |---|---|
/// | 1 | 9 |
/// | 2 | 8 |
/// | 3 | 7 |
/// | 5 | 5 |
/// └---┴---┘
/// ```
/// where both `a ASC` and `b DESC` can describe the table ordering. With
/// `SchemaProperties`, we can keep track of these different valid ordering expressions
/// and treat `a ASC` and `b DESC` as the same ordering requirement.
/// Similarly, as in the table below if we know that Column a and b have always same value.
/// ```text
/// ┌-------┐
/// | a | b |
/// |---|---|
/// | 1 | 1 |
/// | 2 | 2 |
/// | 3 | 3 |
/// | 5 | 5 |
/// └---┴---┘
/// ```
/// We keep track of their equivalence inside schema properties. With this information
/// if partition requirement is Hash(a), and output partitioning is Hash(b). We can deduce that
/// existing partitioning satisfies the requirement.
#[derive(Debug, Clone)]
pub struct SchemaProperties {
    /// Keeps track of expressions that have equivalent value.
    eq_groups: EquivalentGroups,
    /// Keeps track of valid ordering that satisfied table.
    oeq_group: OrderingEquivalentGroup,
    /// Keeps track of expressions that have constant value.
    /// TODO: We do not need to track constants separately, they can be tracked
    ///  inside `eq_groups` as `Literal` expressions.
    constants: Vec<Arc<dyn PhysicalExpr>>,
    schema: SchemaRef,
}

impl SchemaProperties {
    /// Create an empty `SchemaProperties`
    pub fn new(schema: SchemaRef) -> Self {
        Self {
            eq_groups: EquivalentGroups::empty(),
            oeq_group: OrderingEquivalentGroup::empty(),
            constants: vec![],
            schema,
        }
    }

    /// Get schema.
    pub fn schema(&self) -> SchemaRef {
        self.schema.clone()
    }

    /// Return a reference to the ordering equivalent group
    pub fn oeq_group(&self) -> &OrderingEquivalentGroup {
        &self.oeq_group
    }

    /// Return a reference to the equivalent groups
    pub fn eq_groups(&self) -> &EquivalentGroups {
        &self.eq_groups
    }

    /// Add SchemaProperties of the other to the state.
    pub fn extend(mut self, other: SchemaProperties) -> Self {
        self.eq_groups.extend(other.eq_groups);
        self.oeq_group.extend(other.oeq_group);
        self.with_constants(other.constants)
    }

    /// Empties the `oeq_group` inside self, When existing orderings are invalidated.
    pub fn with_empty_ordering_equivalence(mut self) -> Self {
        self.oeq_group = OrderingEquivalentGroup::empty();
        self
    }

    /// Extends `SchemaProperties` by adding ordering inside the `other`
    /// to the `self.oeq_class`.
    pub fn add_ordering_equivalent_group(&mut self, other: OrderingEquivalentGroup) {
        for ordering in other.into_iter() {
            if !self.oeq_group.contains(&ordering) {
                self.oeq_group.push(ordering);
            }
        }
    }

    /// Adds new ordering into the ordering equivalent group.
    pub fn add_new_orderings(&mut self, orderings: &[LexOrdering]) {
        self.oeq_group.add_new_orderings(orderings);
    }

    /// Add new equivalent group to state.
    pub fn add_equivalent_groups(&mut self, other_eq_group: EquivalentGroups) {
        self.eq_groups.extend(other_eq_group);
    }

    /// Adds new equality group into the equivalent groups.
    /// If equalities are new, otherwise extends corresponding group.
    pub fn add_equal_conditions(
        &mut self,
        new_conditions: (&Arc<dyn PhysicalExpr>, &Arc<dyn PhysicalExpr>),
    ) {
        self.eq_groups.add_equal_conditions(new_conditions);
    }

    /// Add physical expression that have constant value to the `self.constants`
    pub fn with_constants(mut self, constants: Vec<Arc<dyn PhysicalExpr>>) -> Self {
        let constants = self.eq_groups.normalize_exprs(&constants);
        constants.into_iter().for_each(|constant| {
            if !physical_exprs_contains(&self.constants, &constant) {
                self.constants.push(constant);
            }
        });
        self
    }

    /// Re-creates `SchemaProperties` given that
    /// schema is re-ordered by `sort_expr` in the argument.
    pub fn with_reorder(mut self, sort_expr: Vec<PhysicalSortExpr>) -> SchemaProperties {
        // TODO: In some cases, existing ordering equivalences may still be valid add this analysis.

        // Normalize sort_expr according to equivalences
        let sort_expr = self.eq_groups.normalize_sort_exprs(&sort_expr);

        // Remove redundant entries from the lex ordering.
        let sort_expr = collapse_lex_ordering(sort_expr);

        // Reset ordering equivalent group with the new ordering.
        // Constants, and equivalent groups are still valid after re-sort.
        // Hence only `oeq_group` is overwritten.
        self.oeq_group = OrderingEquivalentGroup::new(vec![sort_expr]);
        self
    }

    /// Transform `sort_exprs` vector, to standardized version using `eq_groups` and `oeq_group`
    /// Assume `eq_groups` states that `Column a` and `Column b` are aliases.
    /// Also assume `oeq_group` states that ordering `vec![d ASC]` and `vec![a ASC, c ASC]` are
    /// ordering equivalent (in the sense that both describe the ordering of the table).
    /// If the `sort_exprs` input to this function were `vec![b ASC, c ASC]`,
    /// This function converts `sort_exprs` `vec![b ASC, c ASC]` to first `vec![a ASC, c ASC]` after considering `eq_groups`
    /// Then converts `vec![a ASC, c ASC]` to `vec![d ASC]` after considering `oeq_group`.
    /// Standardized version `vec![d ASC]` is used in subsequent operations.
    fn normalize_sort_exprs(
        &self,
        sort_exprs: &[PhysicalSortExpr],
    ) -> Vec<PhysicalSortExpr> {
        // Convert `PhysicalSortExpr`s to `PhysicalSortRequirement`s
        let sort_requirements =
            PhysicalSortRequirement::from_sort_exprs(sort_exprs.iter());
        let normalized_exprs = self.normalize_sort_requirements(&sort_requirements);
        // Convert back `PhysicalSortRequirement`s to `PhysicalSortExpr`s
        PhysicalSortRequirement::to_sort_exprs(normalized_exprs)
    }

    /// This function normalizes `sort_reqs` by
    /// - removing expressions that have constant value from requirement
    /// - replacing sections that are in the `self.oeq_group` with `oeq_group[0]` (e.g standard representative
    ///   version of the group)
    /// - removing sections that satisfies global ordering that are in the post fix of requirement
    ///
    /// Transform `sort_reqs` vector, to standardized version using `eq_groups` and `oeq_group`
    /// Assume `eq_groups` states that `Column a` and `Column b` are aliases.
    /// Also assume `oeq_group` states that ordering `vec![d ASC]` and `vec![a ASC, c ASC]` are
    /// ordering equivalent (in the sense that both describe the ordering of the table).
    /// If the `sort_reqs` input to this function were `vec![b Some(ASC), c None]`,
    /// This function converts `sort_exprs` `vec![b Some(ASC), c None]` to first `vec![a Some(ASC), c None]` after considering `eq_groups`
    /// Then converts `vec![a Some(ASC), c None]` to `vec![d Some(ASC)]` after considering `oeq_group`.
    /// Standardized version `vec![d Some(ASC)]` is used in subsequent operations.
    fn normalize_sort_requirements(
        &self,
        sort_reqs: &[PhysicalSortRequirement],
    ) -> Vec<PhysicalSortRequirement> {
        let normalized_sort_reqs = self.eq_groups.normalize_sort_requirements(sort_reqs);
        let normalized_sort_reqs =
            prune_sort_reqs_with_constants(&normalized_sort_reqs, &self.constants);
        // Prune redundant sections in the requirement.
        collapse_lex_req(normalized_sort_reqs)
    }

    /// Checks whether given ordering requirements are satisfied by provided [PhysicalSortExpr]s.
    pub fn ordering_satisfy(&self, required: Option<&[PhysicalSortExpr]>) -> bool {
        match required {
            None => true,
            Some(required) => self.ordering_satisfy_concrete(required),
        }
    }

    /// Checks whether the required [`PhysicalSortExpr`]s are satisfied by the
    /// any of the existing orderings.
    pub fn ordering_satisfy_concrete(&self, required: &[PhysicalSortExpr]) -> bool {
        // Convert `PhysicalSortExpr`s to `PhysicalSortRequirement`s
        let sort_requirements = PhysicalSortRequirement::from_sort_exprs(required.iter());
        self.ordering_satisfy_requirement_concrete(&sort_requirements)
    }

    /// Checks whether the given [`PhysicalSortRequirement`]s are satisfied by the
    /// provided [`PhysicalSortExpr`]s.
    pub fn ordering_satisfy_requirement(
        &self,
        required: Option<&[PhysicalSortRequirement]>,
    ) -> bool {
        match required {
            None => true,
            Some(required) => self.ordering_satisfy_requirement_concrete(required),
        }
    }

    /// Checks whether the given [`PhysicalSortRequirement`]s are satisfied by the
    /// provided [`PhysicalSortExpr`]s.
    pub fn ordering_satisfy_requirement_concrete(
        &self,
        required: &[PhysicalSortRequirement],
    ) -> bool {
        self.prune_lex_req(required).is_empty()
    }

    /// Checks whether the given [`PhysicalSortRequirement`]s are equal or more
    /// specific than the provided [`PhysicalSortRequirement`]s.
    pub fn requirements_compatible(
        &self,
        provided: Option<&[PhysicalSortRequirement]>,
        required: Option<&[PhysicalSortRequirement]>,
    ) -> bool {
        match (provided, required) {
            (_, None) => true,
            (None, Some(_)) => false,
            (Some(provided), Some(required)) => {
                self.requirements_compatible_concrete(provided, required)
            }
        }
    }

    /// Checks whether the given [`PhysicalSortRequirement`]s are equal or more
    /// specific than the provided [`PhysicalSortRequirement`]s.
    fn requirements_compatible_concrete(
        &self,
        provided: &[PhysicalSortRequirement],
        required: &[PhysicalSortRequirement],
    ) -> bool {
        let provided_normalized = self.normalize_sort_requirements(provided);
        let required_normalized = self.normalize_sort_requirements(required);

        if required_normalized.len() > provided_normalized.len() {
            return false;
        }
        required_normalized
            .into_iter()
            .zip(provided_normalized)
            .all(|(req, given)| given.compatible(&req))
    }

    /// Find the finer requirement among `req1` and `req2`
    /// If `None`, this means that `req1` and `req2` are not compatible
    /// e.g there is no requirement that satisfies both
    pub fn get_finer_ordering<'a>(
        &self,
        req1: &'a [PhysicalSortExpr],
        req2: &'a [PhysicalSortExpr],
    ) -> Option<&'a [PhysicalSortExpr]> {
        let lhs = self.normalize_sort_exprs(req1);
        let rhs = self.normalize_sort_exprs(req2);
        if izip!(lhs.iter(), rhs.iter()).all(|(lhs, rhs)| lhs.eq(rhs)) {
            if lhs.len() > rhs.len() {
                return Some(req1);
            } else {
                return Some(req2);
            }
        }
        // Neither `provided` nor `req` satisfies one another, they are incompatible.
        None
    }

    /// Find the coarser requirement among `req1` and `req2`
    /// If `None`, this means that `req1` and `req2` are not compatible
    pub fn get_meet_ordering<'a>(
        &self,
        req1: &'a [PhysicalSortExpr],
        req2: &'a [PhysicalSortExpr],
    ) -> Option<&'a [PhysicalSortExpr]> {
        let lhs = self.normalize_sort_exprs(req1);
        let rhs = self.normalize_sort_exprs(req2);
        if izip!(lhs.iter(), rhs.iter()).all(|(lhs, rhs)| lhs.eq(rhs)) {
            if lhs.len() < rhs.len() {
                return Some(req1);
            } else {
                return Some(req2);
            }
        }
        // Neither `provided` nor `req` satisfies one another, they are incompatible.
        None
    }

    /// Find the finer requirement among `req1` and `req2`
    /// If `None`, this means that `req1` and `req2` are not compatible
    /// e.g there is no requirement that satisfies both
    pub fn get_finer_requirement<'a>(
        &self,
        req1: &'a [PhysicalSortRequirement],
        req2: &'a [PhysicalSortRequirement],
    ) -> Option<&'a [PhysicalSortRequirement]> {
        let lhs = self.normalize_sort_requirements(req1);
        let rhs = self.normalize_sort_requirements(req2);
        let mut left_finer = false;
        let mut right_finer = false;
        if izip!(lhs.iter(), rhs.iter()).all(|(lhs, rhs)| {
            match (lhs.options, rhs.options) {
                (Some(lhs_opt), Some(rhs_opt)) => {
                    lhs.expr.eq(&rhs.expr) && lhs_opt == rhs_opt
                }
                (Some(_), None) => {
                    left_finer = true;
                    lhs.expr.eq(&rhs.expr)
                }
                (None, Some(_)) => {
                    right_finer = true;
                    lhs.expr.eq(&rhs.expr)
                }
                (None, None) => lhs.expr.eq(&rhs.expr),
            }
        }) {
            if lhs.len() >= rhs.len() && !right_finer {
                return Some(req1);
            } else if rhs.len() >= lhs.len() && !left_finer {
                return Some(req2);
            }
        }
        // Neither `provided` nor `req` satisfies one another, they are incompatible.
        None
    }

    /// This function prunes lexicographical ordering requirement
    /// by removing sections inside `sort_req` that satisfies any of the existing ordering.
    /// Please note that pruned version may not functionally equivalent to the argument.
    /// Empty result means that requirement is already satisfied.
    /// Non-empty result means that requirement is not satisfied.
    /// This util shouldn't e used outside this context.
    fn prune_lex_req(&self, sort_req: &[PhysicalSortRequirement]) -> LexOrderingReq {
        // Make sure to use a standardized version of the requirement
        let mut sort_req = self.normalize_sort_requirements(sort_req);

        // If empty immediately return
        if sort_req.is_empty() {
            return sort_req;
        }

        for ordering in self.oeq_group.iter() {
            // Normalize existing ordering
            let ordering = self.normalize_sort_exprs(ordering);
            let match_indices = ordering
                .iter()
                .map(|elem| {
                    sort_req.iter().position(|sort_req| {
                        elem.satisfy_with_schema(sort_req, &self.schema)
                    })
                })
                .collect::<Vec<_>>();
            let mut match_prefix = vec![];
            for elem in &match_indices {
                if let Some(elem) = elem {
                    if let Some(last) = match_prefix.last() {
                        // Should increase
                        if elem <= last {
                            break;
                        }
                    }
                    match_prefix.push(*elem)
                } else {
                    break;
                }
            }
            // can remove entries at the match_prefix indices
            // Remove with reverse iteration to not invalidate indices
            for idx in match_prefix.iter().rev() {
                sort_req.remove(*idx);
            }
        }
        sort_req
    }

    /// Checks whether `leading_requirement` is contained in any of the ordering
    /// equivalence classes.
    pub fn satisfies_leading_requirement(
        &self,
        leading_requirement: &PhysicalSortRequirement,
    ) -> bool {
        let leading_requirement = self
            .eq_groups
            .normalize_sort_requirement(leading_requirement.clone());
        self.oeq_group().iter().any(|ordering| {
            let ordering = self.eq_groups.normalize_sort_exprs(ordering);
            ordering[0].satisfy_with_schema(&leading_requirement, &self.schema)
        })
    }

    /// Projects `SchemaProperties` according to mapping given in `source_to_target_mapping`.
    pub fn project(
        &self,
        source_to_target_mapping: &ProjectionMapping,
        output_schema: SchemaRef,
    ) -> SchemaProperties {
        let mut projected_properties = SchemaProperties::new(output_schema);

        let projected_eq_groups = self.eq_groups.project(source_to_target_mapping);
        projected_properties.eq_groups = projected_eq_groups;

        let projected_orderings = self
            .oeq_group
            .iter()
            .filter_map(|order| {
                self.eq_groups
                    .project_ordering(source_to_target_mapping, order)
            })
            .collect::<Vec<_>>();

        // if empty, no need to track projected_orderings.
        if !projected_orderings.is_empty() {
            projected_properties.oeq_group =
                OrderingEquivalentGroup::new(projected_orderings);
        }

        for (source, target) in source_to_target_mapping {
            let initial_expr = ExprOrdering::new(source.clone());
            let transformed = initial_expr
                .transform_up(&|expr| update_ordering(expr, self))
                .unwrap();
            if let Some(SortProperties::Ordered(sort_options)) = transformed.state {
                let sort_expr = PhysicalSortExpr {
                    expr: target.clone(),
                    options: sort_options,
                };
                // Push new ordering to the state.
                projected_properties.oeq_group.push(vec![sort_expr]);
            }
        }
        // Remove redundant entries from ordering group if any.
        // projected_properties.oeq_group.remove_redundant_entries();
        projected_properties
    }

    /// Check whether any permutation of the argument has a prefix with existing ordering.
    /// Return indices that describes ordering and their ordering information.
    pub fn set_satisfy(&self, exprs: &[Arc<dyn PhysicalExpr>]) -> Option<Vec<usize>> {
        let exprs_normalized = self.eq_groups.normalize_exprs(exprs);
        let mut best = vec![];

        for ordering in self.oeq_group.iter() {
            let ordering = self.eq_groups.normalize_sort_exprs(ordering);
            let ordering_exprs = ordering
                .iter()
                .map(|sort_expr| sort_expr.expr.clone())
                .collect::<Vec<_>>();
            let mut ordered_indices =
                get_indices_of_exprs_strict(&exprs_normalized, &ordering_exprs);
            ordered_indices.sort();
            // Find out how many expressions of the existing ordering define ordering
            // for expressions in the GROUP BY clause. For example, if the input is
            // ordered by a, b, c, d and we group by b, a, d; the result below would be.
            // 2, meaning 2 elements (a, b) among the GROUP BY columns define ordering.
            let first_n = longest_consecutive_prefix(ordered_indices);
            if first_n > best.len() {
                let ordered_exprs = ordering_exprs[0..first_n].to_vec();
                // Find indices for the GROUP BY expressions such that when we iterate with
                // these indices, we would match existing ordering. For the example above,
                // this would produce 1, 0; meaning 1st and 0th entries (a, b) among the
                // GROUP BY expressions b, a, d match input ordering.
                best = get_indices_of_exprs_strict(&ordered_exprs, &exprs_normalized);
            }
        }

        if best.is_empty() {
            None
        } else {
            Some(best)
        }
    }

    /// Check whether one of the permutation of the exprs satisfies existing ordering.
    /// If so, return indices and their orderings.
    /// None, indicates that there is no permutation that satisfies ordering.
    pub fn set_exactly_satisfy(
        &self,
        exprs: &[Arc<dyn PhysicalExpr>],
    ) -> Option<Vec<usize>> {
        if let Some(indices) = self.set_satisfy(exprs) {
            // A permutation of the exprs satisfies one of the existing orderings.
            if indices.len() == exprs.len() {
                return Some(indices);
            }
        }
        None
    }

    /// Get ordering of the expressions in the argument
    /// Assumes arguments define lexicographical ordering.
    /// None, represents none of the existing ordering satisfy
    /// lexicographical ordering of the exprs.
    pub fn get_lex_ordering(
        &self,
        exprs: &[Arc<dyn PhysicalExpr>],
    ) -> Option<Vec<SortOptions>> {
        let normalized_exprs = self.eq_groups.normalize_exprs(exprs);
        for ordering in self.oeq_group.iter() {
            if normalized_exprs.len() <= ordering.len() {
                let mut ordering_options = vec![];
                for (expr, sort_expr) in izip!(normalized_exprs.iter(), ordering.iter()) {
                    if sort_expr.expr.eq(expr) {
                        ordering_options.push(sort_expr.options);
                    } else {
                        break;
                    }
                    if ordering_options.len() == normalized_exprs.len() {
                        return Some(ordering_options);
                    }
                }
            }
        }
        None
    }
}

/// Calculate ordering equivalence properties for the given join operation.
pub fn join_schema_properties(
    left: &SchemaProperties,
    right: &SchemaProperties,
    join_type: &JoinType,
    join_schema: SchemaRef,
    maintains_input_order: &[bool],
    probe_side: Option<JoinSide>,
    on: &[(Column, Column)],
) -> Result<SchemaProperties> {
    let left_columns_len = left.schema.fields.len();
    let mut new_properties = SchemaProperties::new(join_schema);

    let join_eq_groups =
        left.eq_groups()
            .join(join_type, right.eq_groups(), left_columns_len, on)?;
    new_properties.add_equivalent_groups(join_eq_groups);

    // All joins have 2 children
    assert_eq!(maintains_input_order.len(), 2);
    let left_maintains = maintains_input_order[0];
    let right_maintains = maintains_input_order[1];
    let left_oeq_class = left.oeq_group();
    let right_oeq_class = right.oeq_group();
    match (left_maintains, right_maintains) {
        (true, true) => {
            return Err(DataFusionError::Plan(
                "Cannot maintain ordering of both sides".to_string(),
            ))
        }
        (true, false) => {
            // In this special case, right side ordering can be prefixed with left side ordering.
            if let (Some(JoinSide::Left), JoinType::Inner) = (probe_side, join_type) {
                let updated_right_oeq = get_updated_right_ordering_equivalent_group(
                    join_type,
                    right_oeq_class,
                    left_columns_len,
                )?;

                // Right side ordering equivalence properties should be prepended with
                // those of the left side while constructing output ordering equivalence
                // properties since stream side is the left side.
                //
                // If the right table ordering equivalences contain `b ASC`, and the output
                // ordering of the left table is `a ASC`, then the ordering equivalence `b ASC`
                // for the right table should be converted to `a ASC, b ASC` before it is added
                // to the ordering equivalences of the join.
                let out_oeq_class = left_oeq_class.join_postfix(&updated_right_oeq);
                new_properties.add_ordering_equivalent_group(out_oeq_class);
            } else {
                new_properties.add_ordering_equivalent_group(left_oeq_class.clone());
            }
        }
        (false, true) => {
            let updated_right_oeq = get_updated_right_ordering_equivalent_group(
                join_type,
                right.oeq_group(),
                left_columns_len,
            )?;
            // In this special case, left side ordering can be prefixed with right side ordering.
            if let (Some(JoinSide::Right), JoinType::Inner) = (probe_side, join_type) {
                // Left side ordering equivalence properties should be prepended with
                // those of the right side while constructing output ordering equivalence
                // properties since stream side is the right side.
                //
                // If the right table ordering equivalences contain `b ASC`, and the output
                // ordering of the left table is `a ASC`, then the ordering equivalence `b ASC`
                // for the right table should be converted to `a ASC, b ASC` before it is added
                // to the ordering equivalences of the join.
                let out_oeq_class = updated_right_oeq.join_postfix(left_oeq_class);
                new_properties.add_ordering_equivalent_group(out_oeq_class);
            } else {
                new_properties.add_ordering_equivalent_group(updated_right_oeq);
            }
        }
        (false, false) => {}
    }
    Ok(new_properties)
}

/// Constructs a `SchemaProperties` struct from the given `orderings`.
pub fn schema_properties_helper(
    schema: SchemaRef,
    orderings: &[LexOrdering],
) -> SchemaProperties {
    let mut oep = SchemaProperties::new(schema);
    if orderings.is_empty() {
        // Return an empty `SchemaProperties`:
        oep
    } else {
        oep.add_ordering_equivalent_group(OrderingEquivalentGroup::new(
            orderings.to_vec(),
        ));
        oep
    }
}

/// This function constructs a duplicate-free `LexOrderingReq` by filtering out duplicate
/// entries that have same physical expression inside the given vector `input`.
/// `vec![a Some(Asc), a Some(Desc)]` is collapsed to the `vec![a Some(Asc)]`. Since
/// when same expression is already seen before, following expressions are redundant.
pub fn collapse_lex_req(input: LexOrderingReq) -> LexOrderingReq {
    let mut output = vec![];
    for item in input {
        if output
            .iter()
            .all(|elem: &PhysicalSortRequirement| !elem.expr.eq(&item.expr))
        {
            output.push(item);
        }
    }
    output
}

/// This function constructs a duplicate-free `LexOrdering` by filtering out duplicate
/// entries that have same physical expression inside the given vector `input`.
/// `vec![a ASC, a DESC]` is collapsed to the `vec![a ASC]`. Since
/// when same expression is already seen before, following expressions are redundant.
fn collapse_lex_ordering(input: LexOrdering) -> LexOrdering {
    let mut output = vec![];
    for item in input {
        if output
            .iter()
            .all(|elem: &PhysicalSortExpr| !elem.expr.eq(&item.expr))
        {
            output.push(item);
        }
    }
    output
}

/// Remove ordering requirements that have constant value
fn prune_sort_reqs_with_constants(
    ordering: &[PhysicalSortRequirement],
    constants: &[Arc<dyn PhysicalExpr>],
) -> Vec<PhysicalSortRequirement> {
    ordering
        .iter()
        .filter(|&order| !physical_exprs_contains(constants, &order.expr))
        .cloned()
        .collect()
}

/// Adds the `offset` value to `Column` indices inside `expr`. This function is
/// generally used during the update of the right table schema in join operations.
fn add_offset_to_exprs(
    exprs: Vec<Arc<dyn PhysicalExpr>>,
    offset: usize,
) -> Result<Vec<Arc<dyn PhysicalExpr>>> {
    exprs
        .into_iter()
        .map(|item| add_offset_to_expr(item, offset))
        .collect::<Result<Vec<_>>>()
}

/// Adds the `offset` value to `Column` indices inside `expr`. This function is
/// generally used during the update of the right table schema in join operations.
fn add_offset_to_expr(
    expr: Arc<dyn PhysicalExpr>,
    offset: usize,
) -> Result<Arc<dyn PhysicalExpr>> {
    expr.transform_down(&|e| match e.as_any().downcast_ref::<Column>() {
        Some(col) => Ok(Transformed::Yes(Arc::new(Column::new(
            col.name(),
            offset + col.index(),
        )))),
        None => Ok(Transformed::No(e)),
    })
}

/// Adds the `offset` value to `Column` indices inside `sort_expr.expr`.
fn add_offset_to_sort_expr(
    sort_expr: &PhysicalSortExpr,
    offset: usize,
) -> Result<PhysicalSortExpr> {
    Ok(PhysicalSortExpr {
        expr: add_offset_to_expr(sort_expr.expr.clone(), offset)?,
        options: sort_expr.options,
    })
}

/// Adds the `offset` value to `Column` indices for each `sort_expr.expr`
/// inside `sort_exprs`.
pub fn add_offset_to_lex_ordering(
    sort_exprs: LexOrderingRef,
    offset: usize,
) -> Result<LexOrdering> {
    sort_exprs
        .iter()
        .map(|sort_expr| add_offset_to_sort_expr(sort_expr, offset))
        .collect()
}

/// Calculates the [`SortProperties`] of a given [`ExprOrdering`] node.
/// The node is either a leaf node, or an intermediate node:
/// - If it is a leaf node, the children states are `None`. We directly find
/// the order of the node by looking at the given sort expression and equivalence
/// properties if it is a `Column` leaf, or we mark it as unordered. In the case
/// of a `Literal` leaf, we mark it as singleton so that it can cooperate with
/// some ordered columns at the upper steps.
/// - If it is an intermediate node, the children states matter. Each `PhysicalExpr`
/// and operator has its own rules about how to propagate the children orderings.
/// However, before the children order propagation, it is checked that whether
/// the intermediate node can be directly matched with the sort expression. If there
/// is a match, the sort expression emerges at that node immediately, discarding
/// the order coming from the children.
fn update_ordering(
    mut node: ExprOrdering,
    ordering_equal_properties: &SchemaProperties,
) -> Result<Transformed<ExprOrdering>> {
    let eq_groups = &ordering_equal_properties.eq_groups;
    let oeq_group = &ordering_equal_properties.oeq_group;
    if let Some(children_sort_options) = &node.children_states {
        // We have an intermediate (non-leaf) node, account for its children:
        node.state = Some(node.expr.get_ordering(children_sort_options));
        Ok(Transformed::Yes(node))
    } else if node.expr.as_any().is::<Column>() {
        // We have a Column, which is one of the two possible leaf node types:
        let normalized_expr = eq_groups.normalize_expr(node.expr.clone());
        if let Some(options) = oeq_group.get_ordering(&normalized_expr) {
            node.state = Some(SortProperties::Ordered(options));
            Ok(Transformed::Yes(node))
        } else {
            node.state = None;
            Ok(Transformed::No(node))
        }
    } else {
        // We have a Literal, which is the other possible leaf node type:
        node.state = Some(node.expr.get_ordering(&[]));
        Ok(Transformed::Yes(node))
    }
}

/// Update right table ordering equivalences so that:
/// - They point to valid indices at the output of the join schema, and
/// - They are normalized with respect to equivalence columns.
///
/// To do so, we increment column indices by the size of the left table when
/// join schema consists of a combination of left and right schema (Inner,
/// Left, Full, Right joins). Then, we normalize the sort expressions of
/// ordering equivalences one by one. We make sure that each expression in the
/// ordering equivalence is either:
/// - The head of the one of the equivalent classes, or
/// - Doesn't have an equivalent column.
///
/// This way; once we normalize an expression according to equivalence properties,
/// it can thereafter safely be used for ordering equivalence normalization.
fn get_updated_right_ordering_equivalent_group(
    join_type: &JoinType,
    right_oeq_group: &OrderingEquivalentGroup,
    left_columns_len: usize,
) -> Result<OrderingEquivalentGroup> {
    match join_type {
        // In these modes, indices of the right schema should be offset by
        // the left table size.
        JoinType::Inner | JoinType::Left | JoinType::Full | JoinType::Right => {
            return right_oeq_group.add_offset(left_columns_len)
        }
        _ => {}
    };
    Ok(right_oeq_group.clone())
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::expressions::{col, lit, Column};
    use arrow::datatypes::{DataType, Field, Schema};
    use datafusion_common::Result;

    use crate::physical_expr::physical_exprs_equal;
    use arrow::compute::{lexsort_to_indices, SortColumn};
    use arrow_array::{ArrayRef, RecordBatch, UInt32Array, UInt64Array};
    use arrow_schema::{Fields, SortOptions};
    use rand::rngs::StdRng;
    use rand::{Rng, SeedableRng};
    use std::sync::Arc;

    // Generate a schema which consists of 7 columns (a, b, c, d, e, f, g)
    fn create_test_schema() -> Result<SchemaRef> {
        let a = Field::new("a", DataType::Int32, true);
        let b = Field::new("b", DataType::Int32, true);
        let c = Field::new("c", DataType::Int32, true);
        let d = Field::new("d", DataType::Int32, true);
        let e = Field::new("e", DataType::Int32, true);
        let f = Field::new("f", DataType::Int32, true);
        let g = Field::new("g", DataType::Int32, true);
        let schema = Arc::new(Schema::new(vec![a, b, c, d, e, f, g]));

        Ok(schema)
    }

    /// Construct a schema with following properties
    /// Schema satisfied following orderings:
    /// [a ASC], [d ASC, b ASC], [e DESC, f ASC, g ASC]
    /// and
    /// Column [a=c] (e.g they are aliases).
    fn create_test_params() -> Result<(SchemaRef, SchemaProperties)> {
        let test_schema = create_test_schema()?;
        let col_a_expr = &col("a", &test_schema)?;
        let col_b_expr = &col("b", &test_schema)?;
        let col_c_expr = &col("c", &test_schema)?;
        let col_d_expr = &col("d", &test_schema)?;
        let col_e_expr = &col("e", &test_schema)?;
        let col_f_expr = &col("f", &test_schema)?;
        let col_g_expr = &col("g", &test_schema)?;
        let mut schema_properties = SchemaProperties::new(test_schema.clone());
        schema_properties.add_equal_conditions((&col_a_expr, &col_c_expr));

        let option1 = SortOptions {
            descending: false,
            nulls_first: false,
        };
        let option2 = SortOptions {
            descending: true,
            nulls_first: true,
        };
        schema_properties.add_new_orderings(&[
            vec![PhysicalSortExpr {
                expr: col_a_expr.clone(),
                options: option1,
            }],
            vec![
                PhysicalSortExpr {
                    expr: col_d_expr.clone(),
                    options: option1,
                },
                PhysicalSortExpr {
                    expr: col_b_expr.clone(),
                    options: option1,
                },
            ],
            vec![
                PhysicalSortExpr {
                    expr: col_e_expr.clone(),
                    options: option2,
                },
                PhysicalSortExpr {
                    expr: col_f_expr.clone(),
                    options: option1,
                },
                PhysicalSortExpr {
                    expr: col_g_expr.clone(),
                    options: option1,
                },
            ],
        ]);
        Ok((test_schema, schema_properties))
    }

    // Generate a schema which consists of 6 columns (a, b, c, d, e, f)
    fn create_test_schema_2() -> Result<SchemaRef> {
        let a = Field::new("a", DataType::Int32, true);
        let b = Field::new("b", DataType::Int32, true);
        let c = Field::new("c", DataType::Int32, true);
        let d = Field::new("d", DataType::Int32, true);
        let e = Field::new("e", DataType::Int32, true);
        let f = Field::new("f", DataType::Int32, true);
        let schema = Arc::new(Schema::new(vec![a, b, c, d, e, f]));

        Ok(schema)
    }

    /// Construct a schema with following properties
    /// Schema satisfied following orderings:
    /// [a ASC, b ASC], [c ASC, d ASC, e ASC]
    /// and
    /// Column [a=f] (e.g they are aliases).
    fn create_test_params_2() -> Result<(SchemaRef, SchemaProperties)> {
        let test_schema = create_test_schema_2()?;
        let col_a_expr = &col("a", &test_schema)?;
        let col_b_expr = &col("b", &test_schema)?;
        let col_c_expr = &col("c", &test_schema)?;
        let col_d_expr = &col("d", &test_schema)?;
        let col_e_expr = &col("e", &test_schema)?;
        let col_f_expr = &col("f", &test_schema)?;
        let mut schema_properties = SchemaProperties::new(test_schema.clone());
        schema_properties.add_equal_conditions((&col_a_expr, &col_f_expr));

        let option1 = SortOptions {
            descending: false,
            nulls_first: false,
        };
        schema_properties.add_new_orderings(&[
            vec![
                PhysicalSortExpr {
                    expr: col_a_expr.clone(),
                    options: option1,
                },
                PhysicalSortExpr {
                    expr: col_b_expr.clone(),
                    options: option1,
                },
            ],
            vec![
                PhysicalSortExpr {
                    expr: col_c_expr.clone(),
                    options: option1,
                },
                PhysicalSortExpr {
                    expr: col_d_expr.clone(),
                    options: option1,
                },
                PhysicalSortExpr {
                    expr: col_e_expr.clone(),
                    options: option1,
                },
            ],
        ]);
        Ok((test_schema, schema_properties))
    }

    // Convert each tuple to PhysicalSortRequirement
    fn convert_to_requirement(
        in_data: &[(&Arc<dyn PhysicalExpr>, Option<SortOptions>)],
    ) -> Vec<PhysicalSortRequirement> {
        in_data
            .iter()
            .map(|(expr, options)| {
                PhysicalSortRequirement::new((*expr).clone(), *options)
            })
            .collect::<Vec<_>>()
    }

    #[test]
    fn add_equal_conditions_test() -> Result<()> {
        let schema = Arc::new(Schema::new(vec![
            Field::new("a", DataType::Int64, true),
            Field::new("b", DataType::Int64, true),
            Field::new("c", DataType::Int64, true),
            Field::new("x", DataType::Int64, true),
            Field::new("y", DataType::Int64, true),
        ]));

        let mut schema_properties = SchemaProperties::new(schema);
        let col_a_expr = Arc::new(Column::new("a", 0)) as Arc<dyn PhysicalExpr>;
        let col_b_expr = Arc::new(Column::new("b", 1)) as Arc<dyn PhysicalExpr>;
        let col_c_expr = Arc::new(Column::new("c", 2)) as Arc<dyn PhysicalExpr>;
        let col_x_expr = Arc::new(Column::new("x", 3)) as Arc<dyn PhysicalExpr>;
        let col_y_expr = Arc::new(Column::new("y", 4)) as Arc<dyn PhysicalExpr>;

        let new_condition = (&col_a_expr, &col_b_expr);
        schema_properties.add_equal_conditions(new_condition);
        assert_eq!(schema_properties.eq_groups().len(), 1);

        let new_condition = (&col_b_expr, &col_a_expr);
        schema_properties.add_equal_conditions(new_condition);
        assert_eq!(schema_properties.eq_groups().len(), 1);
        let eq_groups = &schema_properties.eq_groups().inner[0];
        assert_eq!(eq_groups.len(), 2);
        assert!(physical_exprs_contains(eq_groups, &col_a_expr));
        assert!(physical_exprs_contains(eq_groups, &col_b_expr));

        let new_condition = (&col_b_expr, &col_c_expr);
        schema_properties.add_equal_conditions(new_condition);
        assert_eq!(schema_properties.eq_groups().len(), 1);
        let eq_groups = &schema_properties.eq_groups().inner[0];
        assert_eq!(eq_groups.len(), 3);
        assert!(physical_exprs_contains(eq_groups, &col_a_expr));
        assert!(physical_exprs_contains(eq_groups, &col_b_expr));
        assert!(physical_exprs_contains(eq_groups, &col_c_expr));

        // This is a new set of equality. Hence equivalent class count should be 2.
        let new_condition = (&col_x_expr, &col_y_expr);
        schema_properties.add_equal_conditions(new_condition);
        assert_eq!(schema_properties.eq_groups().len(), 2);

        // This equality bridges distinct equality sets.
        // Hence equivalent class count should decrease from 2 to 1.
        let new_condition = (&col_x_expr, &col_a_expr);
        schema_properties.add_equal_conditions(new_condition);
        assert_eq!(schema_properties.eq_groups().len(), 1);
        let eq_groups = &schema_properties.eq_groups().inner[0];
        assert_eq!(eq_groups.len(), 5);
        assert!(physical_exprs_contains(eq_groups, &col_a_expr));
        assert!(physical_exprs_contains(eq_groups, &col_b_expr));
        assert!(physical_exprs_contains(eq_groups, &col_c_expr));
        assert!(physical_exprs_contains(eq_groups, &col_x_expr));
        assert!(physical_exprs_contains(eq_groups, &col_y_expr));

        Ok(())
    }

    #[test]
    fn project_equivalence_properties_test() -> Result<()> {
        let input_schema = Arc::new(Schema::new(vec![
            Field::new("a", DataType::Int64, true),
            Field::new("b", DataType::Int64, true),
            Field::new("c", DataType::Int64, true),
        ]));

        let mut input_properties = SchemaProperties::new(input_schema);
        let col_a_expr = Arc::new(Column::new("a", 0)) as Arc<dyn PhysicalExpr>;
        let col_b_expr = Arc::new(Column::new("b", 1)) as Arc<dyn PhysicalExpr>;
        let col_c_expr = Arc::new(Column::new("c", 2)) as Arc<dyn PhysicalExpr>;

        let new_condition = (&col_a_expr, &col_b_expr);
        input_properties.add_equal_conditions(new_condition);
        let new_condition = (&col_b_expr, &col_c_expr);
        input_properties.add_equal_conditions(new_condition);

        let out_schema = Arc::new(Schema::new(vec![
            Field::new("a1", DataType::Int64, true),
            Field::new("a2", DataType::Int64, true),
            Field::new("a3", DataType::Int64, true),
            Field::new("a4", DataType::Int64, true),
        ]));

        let col_a1_expr = Arc::new(Column::new("a1", 0)) as Arc<dyn PhysicalExpr>;
        let col_a2_expr = Arc::new(Column::new("a2", 1)) as Arc<dyn PhysicalExpr>;
        let col_a3_expr = Arc::new(Column::new("a3", 2)) as Arc<dyn PhysicalExpr>;
        let col_a4_expr = Arc::new(Column::new("a4", 2)) as Arc<dyn PhysicalExpr>;
        let source_to_target_mapping = vec![
            (col_a_expr.clone(), col_a1_expr.clone()),
            (col_a_expr.clone(), col_a2_expr.clone()),
            (col_a_expr.clone(), col_a3_expr.clone()),
            (col_a_expr.clone(), col_a4_expr.clone()),
        ];
        let out_properties =
            input_properties.project(&source_to_target_mapping, out_schema);

        assert_eq!(out_properties.eq_groups().len(), 1);
        let eq_class = &out_properties.eq_groups().inner[0];
        assert_eq!(eq_class.len(), 4);
        assert!(physical_exprs_contains(eq_class, &col_a1_expr));
        assert!(physical_exprs_contains(eq_class, &col_a2_expr));
        assert!(physical_exprs_contains(eq_class, &col_a3_expr));
        assert!(physical_exprs_contains(eq_class, &col_a4_expr));

        Ok(())
    }

    #[test]
    fn test_ordering_satisfy() -> Result<()> {
        let crude = vec![PhysicalSortExpr {
            expr: Arc::new(Column::new("a", 0)),
            options: SortOptions::default(),
        }];
        let finer = vec![
            PhysicalSortExpr {
                expr: Arc::new(Column::new("a", 0)),
                options: SortOptions::default(),
            },
            PhysicalSortExpr {
                expr: Arc::new(Column::new("b", 1)),
                options: SortOptions::default(),
            },
        ];
        // finer ordering satisfies, crude ordering shoul return true
        let empty_schema = &Arc::new(Schema::empty());
        let mut schema_properties = SchemaProperties::new(empty_schema.clone());
        schema_properties.oeq_group.push(finer.clone());
        assert!(schema_properties.ordering_satisfy(Some(&crude)));

        // Crude ordering doesn't satisfy finer ordering. should return false
        let mut schema_properties = SchemaProperties::new(empty_schema.clone());
        schema_properties.oeq_group.push(crude.clone());
        assert!(!schema_properties.ordering_satisfy(Some(&finer)));
        Ok(())
    }

    #[test]
    fn test_ordering_satisfy_with_equivalence() -> Result<()> {
        // Schema satisfies following orderings:
        // [a ASC], [d ASC, b ASC], [e DESC, f ASC, g ASC]
        // and
        // Column [a=c] (e.g they are aliases).
        let (test_schema, schema_properties) = create_test_params()?;
        let col_a = &col("a", &test_schema)?;
        let col_b = &col("b", &test_schema)?;
        let col_c = &col("c", &test_schema)?;
        let col_d = &col("d", &test_schema)?;
        let col_e = &col("e", &test_schema)?;
        let col_f = &col("f", &test_schema)?;
        let col_g = &col("g", &test_schema)?;
        let option1 = SortOptions {
            descending: false,
            nulls_first: false,
        };
        let option2 = SortOptions {
            descending: true,
            nulls_first: true,
        };
        let table_data_with_properties =
            generate_table_for_schema_properties(&schema_properties, 625, 5)?;

        // First element in the tuple stores vector of requirement, second element is the expected return value for ordering_satisfy function
        let requirements = vec![
            // `a ASC NULLS LAST`, expects `ordering_satisfy` to be `true`, since existing ordering `a ASC NULLS LAST, b ASC NULLS LAST` satisfies it
            (vec![(col_a, option1)], true),
            (vec![(col_a, option2)], false),
            // Test whether equivalence works as expected
            (vec![(col_c, option1)], true),
            (vec![(col_c, option2)], false),
            // Test whether ordering equivalence works as expected
            (vec![(col_d, option1)], true),
            (vec![(col_d, option1), (col_b, option1)], true),
            (vec![(col_d, option2), (col_b, option1)], false),
            (
                vec![(col_e, option2), (col_f, option1), (col_g, option1)],
                true,
            ),
            (vec![(col_e, option2), (col_f, option1)], true),
            (vec![(col_e, option1), (col_f, option1)], false),
            (vec![(col_e, option2), (col_b, option1)], false),
            (vec![(col_e, option1), (col_b, option1)], false),
            (
                vec![
                    (col_d, option1),
                    (col_b, option1),
                    (col_d, option1),
                    (col_b, option1),
                ],
                true,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_b, option1),
                    (col_e, option2),
                    (col_f, option1),
                ],
                true,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_b, option1),
                    (col_e, option2),
                    (col_b, option1),
                ],
                true,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_b, option1),
                    (col_d, option2),
                    (col_b, option1),
                ],
                true,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_b, option1),
                    (col_e, option1),
                    (col_f, option1),
                ],
                false,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_b, option1),
                    (col_e, option1),
                    (col_b, option1),
                ],
                false,
            ),
            (vec![(col_d, option1), (col_e, option2)], true),
            (
                vec![(col_d, option1), (col_c, option1), (col_b, option1)],
                true,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_e, option2),
                    (col_f, option1),
                    (col_b, option1),
                ],
                true,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_e, option2),
                    (col_c, option1),
                    (col_b, option1),
                ],
                true,
            ),
            (
                vec![
                    (col_d, option1),
                    (col_e, option2),
                    (col_b, option1),
                    (col_f, option1),
                ],
                true,
            ),
        ];

        for (cols, expected) in requirements {
            let err_msg = format!("Error in test case:{cols:?}");
            let required = cols
                .into_iter()
                .map(|(expr, options)| PhysicalSortExpr {
                    expr: expr.clone(),
                    options,
                })
                .collect::<Vec<_>>();

            assert_eq!(
                is_table_same_after_sort(
                    required.clone(),
                    table_data_with_properties.clone()
                )?,
                expected
            );
            let required = Some(&required[..]);
            assert_eq!(
                schema_properties.ordering_satisfy(required),
                expected,
                "{err_msg}"
            );
        }
        Ok(())
    }

    #[test]
    fn test_ordering_satisfy_with_equivalence_random() -> Result<()> {
        // Number of random tests
        let n_test = 10000usize;
        let n_req_max = 5usize;
        let option1 = SortOptions {
            descending: false,
            nulls_first: false,
        };
        // Schema satisfies following orderings:
        // [a ASC, b ASC], [c ASC, d ASC, e ASC]
        // and
        // Column [a=f] (e.g they are aliases).
        let (_test_schema, schema_properties) = create_test_params_2()?;
        let table_data_with_properties =
            generate_table_for_schema_properties(&schema_properties, 625, 5)?;

        // use a random number for values
        let mut rng = StdRng::seed_from_u64(23);
        let schema = schema_properties.schema();
        let n_schema = schema.fields.len();
        for _test_id in 0..n_test {
            let n_req = rng.gen_range(0..n_req_max);
            let requirement = (0..n_req)
                .map(|_idx| {
                    let col_idx = rng.gen_range(0..n_schema);
                    let col_expr = col(schema.fields[col_idx].name(), &schema)?;
                    Ok(PhysicalSortExpr {
                        expr: col_expr,
                        options: option1,
                    })
                })
                .collect::<Result<Vec<_>>>()?;
            let err_msg = format!("Error in test case:{requirement:?}");
            let expected = is_table_same_after_sort(
                requirement.clone(),
                table_data_with_properties.clone(),
            )?;
            assert_eq!(
                schema_properties.ordering_satisfy_concrete(&requirement),
                expected,
                "{err_msg}"
            );
        }

        Ok(())
    }

    #[test]
    fn test_ordering_satisfy_different_lengths() -> Result<()> {
        let test_schema = create_test_schema()?;
        let col_a = col("a", &test_schema)?;
        let col_b = col("b", &test_schema)?;
        let col_c = col("c", &test_schema)?;
        let col_d = col("d", &test_schema)?;
        let col_e = col("e", &test_schema)?;
        let col_f = col("f", &test_schema)?;
        let options = SortOptions {
            descending: false,
            nulls_first: false,
        };
        // Column a and c are aliases.
        let mut schema_properties = SchemaProperties::new(test_schema);
        schema_properties.add_equal_conditions((&col_a, &col_c));

        // Column a and e are ordering equivalent (e.g global ordering of the table can be described both as a ASC and e ASC.)
        schema_properties.add_new_orderings(&[
            vec![PhysicalSortExpr {
                expr: col_a.clone(),
                options,
            }],
            vec![PhysicalSortExpr {
                expr: col_e.clone(),
                options,
            }],
        ]);

        // Column a and d,f are ordering equivalent (e.g global ordering of the table can be described both as [a ASC] and [d ASC, f ASC].)
        schema_properties.add_new_orderings(&[
            vec![PhysicalSortExpr {
                expr: col_a.clone(),
                options,
            }],
            vec![
                PhysicalSortExpr {
                    expr: col_d.clone(),
                    options,
                },
                PhysicalSortExpr {
                    expr: col_f.clone(),
                    options,
                },
            ],
        ]);
        // All of the orderings [a ASC], [d ASC, f ASC], [e ASC]]
        // are valid for the table
        // Also Columns a and c are equal

        let sort_req_a = PhysicalSortExpr {
            expr: col_a.clone(),
            options,
        };
        let sort_req_b = PhysicalSortExpr {
            expr: col_b.clone(),
            options,
        };
        let sort_req_c = PhysicalSortExpr {
            expr: col_c.clone(),
            options,
        };
        let sort_req_d = PhysicalSortExpr {
            expr: col_d.clone(),
            options,
        };
        let sort_req_e = PhysicalSortExpr {
            expr: col_e.clone(),
            options,
        };
        let sort_req_f = PhysicalSortExpr {
            expr: col_f.clone(),
            options,
        };

        assert!(schema_properties.ordering_satisfy_concrete(
            // After normalization would be a ASC
            &[sort_req_c.clone(), sort_req_a.clone(), sort_req_e.clone(),],
        ));
        assert!(!schema_properties.ordering_satisfy_concrete(
            // After normalization would be a ASC, b ASC
            // which is not satisfied
            &[sort_req_c.clone(), sort_req_b.clone(),],
        ));

        assert!(schema_properties.ordering_satisfy_concrete(
            // After normalization would be a ASC
            &[sort_req_c.clone(), sort_req_d.clone(),],
        ));

        assert!(!schema_properties.ordering_satisfy_concrete(
            // After normalization would be a ASC, b ASC
            // which is not satisfied
            &[sort_req_d.clone(), sort_req_f.clone(), sort_req_b.clone(),],
        ));

        assert!(schema_properties.ordering_satisfy_concrete(
            // After normalization would be a ASC
            // which is satisfied
            &[sort_req_d.clone(), sort_req_f.clone()],
        ));

        Ok(())
    }

    #[test]
    fn test_bridge_groups() -> Result<()> {
        let entries = vec![
            vec![lit(1), lit(2), lit(3)],
            vec![lit(2), lit(4), lit(5)],
            vec![lit(11), lit(12), lit(9)],
            vec![lit(7), lit(6), lit(5)],
        ];
        // Expected is a bit weird. However, what we care is they expected contains distinct groups.
        // where there is no common entry between any groups.
        // Since we do check for vector equality, this version should be used during comparison in the test.
        let expected = vec![
            vec![lit(11), lit(12), lit(9)],
            vec![lit(7), lit(6), lit(5), lit(2), lit(4), lit(1), lit(3)],
        ];
        let mut eq_groups = EquivalentGroups::new(entries);
        eq_groups.bridge_groups();

        let eq_groups = eq_groups.inner;
        assert_eq!(eq_groups.len(), expected.len());
        assert_eq!(eq_groups.len(), 2);

        assert!(physical_exprs_equal(&eq_groups[0], &expected[0]));
        assert!(physical_exprs_equal(&eq_groups[1], &expected[1]));
        Ok(())
    }

    #[test]
    fn test_remove_redundant_entries() -> Result<()> {
        let entries = vec![
            vec![lit(1), lit(1), lit(2)],
            // This group is meaningless should be removed
            vec![lit(3), lit(3)],
            vec![lit(4), lit(5), lit(6)],
        ];
        // Expected is a bit weird. However, what we care is they expected contains distinct groups.
        // where there is no common entry between any groups.
        // Since we do check for vector equality, this version should be used during comparison in the test.
        let expected = vec![vec![lit(1), lit(2)], vec![lit(4), lit(5), lit(6)]];
        let mut eq_groups = EquivalentGroups::new(entries);
        eq_groups.remove_redundant_entries();

        let eq_groups = eq_groups.inner;
        assert_eq!(eq_groups.len(), expected.len());
        assert_eq!(eq_groups.len(), 2);

        assert!(physical_exprs_equal(&eq_groups[0], &expected[0]));
        assert!(physical_exprs_equal(&eq_groups[1], &expected[1]));
        Ok(())
    }

    #[test]
    fn test_get_updated_right_ordering_equivalence_properties() -> Result<()> {
        let join_type = JoinType::Inner;

        let options = SortOptions::default();
        let right_oeq_class = OrderingEquivalentGroup::new(vec![
            vec![
                PhysicalSortExpr {
                    expr: Arc::new(Column::new("x", 0)),
                    options,
                },
                PhysicalSortExpr {
                    expr: Arc::new(Column::new("y", 1)),
                    options,
                },
            ],
            vec![
                PhysicalSortExpr {
                    expr: Arc::new(Column::new("z", 2)),
                    options,
                },
                PhysicalSortExpr {
                    expr: Arc::new(Column::new("w", 3)),
                    options,
                },
            ],
        ]);

        let left_columns_len = 4;

        let fields: Fields = ["a", "b", "c", "d", "x", "y", "z", "w"]
            .into_iter()
            .map(|name| Field::new(name, DataType::Int32, true))
            .collect();

        let schema = Schema::new(fields);
        let col_a_expr = col("a", &schema)?;
        let col_d_expr = col("d", &schema)?;
        let col_x_expr = col("x", &schema)?;
        let col_y_expr = col("y", &schema)?;
        let col_z_expr = col("z", &schema)?;
        let col_w_expr = col("w", &schema)?;

        let mut join_schema_properties = SchemaProperties::new(Arc::new(schema));
        join_schema_properties.add_equal_conditions((&col_a_expr, &col_x_expr));
        join_schema_properties.add_equal_conditions((&col_d_expr, &col_w_expr));

        let result = get_updated_right_ordering_equivalent_group(
            &join_type,
            &right_oeq_class,
            left_columns_len,
        )?;
        join_schema_properties.add_ordering_equivalent_group(result);
        let result = join_schema_properties.oeq_group().clone();

        let expected = OrderingEquivalentGroup::new(vec![
            vec![
                PhysicalSortExpr {
                    expr: col_x_expr,
                    options,
                },
                PhysicalSortExpr {
                    expr: col_y_expr,
                    options,
                },
            ],
            vec![
                PhysicalSortExpr {
                    expr: col_z_expr,
                    options,
                },
                PhysicalSortExpr {
                    expr: col_w_expr,
                    options,
                },
            ],
        ]);

        assert_eq!(result, expected);

        Ok(())
    }

    // Check whether table will stay the same after ordered according to requirement
    // given. If so it means that required ordering is already satisfied (according to
    // random data).
    fn is_table_same_after_sort(
        mut required_ordering: Vec<PhysicalSortExpr>,
        batch: RecordBatch,
    ) -> Result<bool> {
        let schema = batch.schema();
        let n_row = batch.num_rows() as u64;
        let mut sort_columns = vec![];
        let new_arr = Arc::new(UInt64Array::from_iter_values(0..n_row)) as ArrayRef;
        let mut cols = batch.columns().to_vec();
        cols.push(new_arr);
        let mut fields = schema.fields.to_vec();
        let new_col_expr =
            Arc::new(Column::new("unique", fields.len())) as Arc<dyn PhysicalExpr>;
        fields.push(Arc::new(Field::new("unique", DataType::UInt64, false)));
        let schema = Arc::new(Schema::new(fields));
        let batch = RecordBatch::try_new(schema.clone(), cols)?;

        // Add a unique ordering to the requirement to make resulting indices deterministic
        required_ordering.push(PhysicalSortExpr {
            expr: new_col_expr,
            options: Default::default(),
        });

        for elem in required_ordering.into_iter() {
            let (idx, _field) = schema
                .column_with_name(
                    elem.expr.as_any().downcast_ref::<Column>().unwrap().name(),
                )
                .unwrap();
            let arr = batch.column(idx);
            sort_columns.push(SortColumn {
                values: arr.clone(),
                options: Some(elem.options),
            })
        }
        let indices = lexsort_to_indices(&sort_columns, None)?;
        let no_change = UInt32Array::from_iter_values(0..n_row as u32);
        Ok(indices == no_change)
    }

    fn get_representative_arr(
        eq_group: &[Arc<dyn PhysicalExpr>],
        existing_vec: &[Option<ArrayRef>],
        schema: SchemaRef,
    ) -> Option<ArrayRef> {
        for expr in eq_group.iter() {
            let col = expr.as_any().downcast_ref::<Column>().unwrap();
            let (idx, _field) = schema.column_with_name(col.name()).unwrap();
            if let Some(res) = &existing_vec[idx] {
                return Some(res.clone());
            }
        }
        None
    }

    // Generate a table that satisfies schema properties, in terms of ordering equivalences.
    fn generate_table_for_schema_properties(
        schema_properties: &SchemaProperties,
        n_elem: usize,
        n_distinct: usize,
    ) -> Result<RecordBatch> {
        // use a random number for values
        let mut rng = StdRng::seed_from_u64(23);

        let schema = schema_properties.schema();

        let mut schema_vec = vec![None; schema.fields.len()];
        for ordering in schema_properties.oeq_group.iter() {
            let mut sort_columns = vec![];
            let mut indices = vec![];
            for PhysicalSortExpr { expr, options } in ordering {
                let col = expr.as_any().downcast_ref::<Column>().unwrap();
                let (idx, _field) = schema.column_with_name(col.name()).unwrap();
                let mut arr: Vec<u64> = vec![0; n_elem];
                arr.iter_mut().for_each(|v| {
                    *v = rng.gen_range(0..n_distinct) as u64;
                });
                let arr = Arc::new(UInt64Array::from_iter_values(arr)) as ArrayRef;
                sort_columns.push(SortColumn {
                    values: arr,
                    options: Some(*options),
                });
                indices.push(idx);
            }
            let sort_arrs = arrow::compute::lexsort(&sort_columns, None)?;
            for (idx, arr) in izip!(indices, sort_arrs) {
                schema_vec[idx] = Some(arr);
            }
        }

        for eq_group in schema_properties.eq_groups.iter() {
            let arr = if let Some(arr) =
                get_representative_arr(eq_group, &schema_vec, schema.clone())
            {
                arr
            } else {
                let mut arr: Vec<u64> = vec![0; n_elem];
                arr.iter_mut().for_each(|v| {
                    *v = rng.gen_range(0..n_distinct) as u64;
                });
                Arc::new(UInt64Array::from_iter_values(arr)) as ArrayRef
            };
            for expr in eq_group {
                let col = expr.as_any().downcast_ref::<Column>().unwrap();
                let (idx, _field) = schema.column_with_name(col.name()).unwrap();
                schema_vec[idx] = Some(arr.clone());
            }
        }

        let res = schema_vec
            .into_iter()
            .zip(schema.fields.iter())
            .map(|(elem, field)| (field.name(), elem.unwrap()))
            .collect::<Vec<_>>();
        let res = RecordBatch::try_from_iter(res)?;
        Ok(res)
    }

    #[test]
    fn test_schema_normalize_expr_with_equivalence() -> Result<()> {
        let col_a = &Column::new("a", 0);
        let col_b = &Column::new("b", 1);
        let col_c = &Column::new("c", 2);
        // Assume that column a and c are aliases.
        let (_test_schema, schema_properties) = create_test_params()?;

        let col_a_expr = Arc::new(col_a.clone()) as Arc<dyn PhysicalExpr>;
        let col_b_expr = Arc::new(col_b.clone()) as Arc<dyn PhysicalExpr>;
        let col_c_expr = Arc::new(col_c.clone()) as Arc<dyn PhysicalExpr>;
        // Test cases for equivalence normalization,
        // First entry in the tuple is argument, second entry is expected result after normalization.
        let expressions = vec![
            // Normalized version of the column a and c should go to a (since a is head)
            (&col_a_expr, &col_a_expr),
            (&col_c_expr, &col_a_expr),
            // Cannot normalize column b
            (&col_b_expr, &col_b_expr),
        ];
        let eq_groups = schema_properties.eq_groups();
        for (expr, expected_eq) in expressions {
            assert!(
                expected_eq.eq(&eq_groups.normalize_expr(expr.clone())),
                "error in test: expr: {expr:?}"
            );
        }

        Ok(())
    }

    #[test]
    fn test_schema_normalize_sort_requirement_with_equivalence() -> Result<()> {
        let option1 = SortOptions {
            descending: false,
            nulls_first: false,
        };
        // Assume that column a and c are aliases.
        let (test_schema, schema_properties) = create_test_params()?;
        let col_a_expr = &col("a", &test_schema)?;
        let _col_b_expr = &col("b", &test_schema)?;
        let col_c_expr = &col("c", &test_schema)?;
        let col_d_expr = &col("d", &test_schema)?;
        let _col_e_expr = &col("e", &test_schema)?;

        // Test cases for equivalence normalization
        // First entry in the tuple is PhysicalExpr, second entry is its ordering, third entry is result after normalization.
        let expressions = vec![
            (
                vec![PhysicalSortRequirement {
                    expr: col_a_expr.clone(),
                    options: Some(option1),
                }],
                vec![PhysicalSortRequirement {
                    expr: col_a_expr.clone(),
                    options: Some(option1),
                }],
            ),
            // In the normalized version column c should be replace with column a
            (
                vec![PhysicalSortRequirement {
                    expr: col_c_expr.clone(),
                    options: Some(option1),
                }],
                vec![PhysicalSortRequirement {
                    expr: col_a_expr.clone(),
                    options: Some(option1),
                }],
            ),
            (
                vec![PhysicalSortRequirement {
                    expr: col_c_expr.clone(),
                    options: None,
                }],
                vec![PhysicalSortRequirement {
                    expr: col_a_expr.clone(),
                    options: None,
                }],
            ),
            (
                vec![PhysicalSortRequirement {
                    expr: col_d_expr.clone(),
                    options: Some(option1),
                }],
                vec![PhysicalSortRequirement {
                    expr: col_d_expr.clone(),
                    options: Some(option1),
                }],
            ),
        ];
        for (arg, expected) in expressions.into_iter() {
            let normalized = schema_properties.normalize_sort_requirements(&arg);
            assert!(
                expected.eq(&normalized),
                "error in test: arg: {arg:?}, expected: {expected:?}, normalized: {normalized:?}"
            );
        }

        Ok(())
    }

    #[test]
    fn test_normalize_sort_reqs() -> Result<()> {
        // Schema satisfies following properties
        // a=c
        // and following orderings are valid
        // [a ASC], [d ASC, b ASC], [e DESC, f ASC, g ASC]
        let (test_schema, schema_properties) = create_test_params()?;
        let col_a = &col("a", &test_schema)?;
        let col_b = &col("b", &test_schema)?;
        let col_c = &col("c", &test_schema)?;
        let col_d = &col("d", &test_schema)?;
        let col_e = &col("e", &test_schema)?;
        let col_f = &col("f", &test_schema)?;
        let option1 = SortOptions {
            descending: false,
            nulls_first: false,
        };
        let option2 = SortOptions {
            descending: true,
            nulls_first: true,
        };
        // First element in the tuple stores vector of requirement, second element is the expected return value for ordering_satisfy function
        let requirements = vec![
            (vec![(col_a, Some(option1))], vec![(col_a, Some(option1))]),
            (vec![(col_a, Some(option2))], vec![(col_a, Some(option2))]),
            (vec![(col_a, None)], vec![(col_a, None)]),
            // Test whether equivalence works as expected
            (vec![(col_c, Some(option1))], vec![(col_a, Some(option1))]),
            (vec![(col_c, None)], vec![(col_a, None)]),
            // Test whether ordering equivalence works as expected
            (
                vec![(col_d, Some(option1)), (col_b, Some(option1))],
                vec![(col_d, Some(option1)), (col_b, Some(option1))],
            ),
            (
                vec![(col_d, None), (col_b, None)],
                vec![(col_d, None), (col_b, None)],
            ),
            (
                vec![(col_e, Some(option2)), (col_f, Some(option1))],
                vec![(col_e, Some(option2)), (col_f, Some(option1))],
            ),
            // We should be able to normalize in compatible requirements also (not exactly equal)
            (
                vec![(col_e, Some(option2)), (col_f, None)],
                vec![(col_e, Some(option2)), (col_f, None)],
            ),
            (
                vec![(col_e, None), (col_f, None)],
                vec![(col_e, None), (col_f, None)],
            ),
        ];

        for (reqs, expected_normalized) in requirements.into_iter() {
            let req = convert_to_requirement(&reqs);
            let expected_normalized = convert_to_requirement(&expected_normalized);

            assert_eq!(
                schema_properties.normalize_sort_requirements(&req),
                expected_normalized
            );
        }
        Ok(())
    }
}
